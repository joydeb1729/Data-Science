{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Hyperparameter Tuning**\n",
    "\n",
    "Hyperparameter tuning is the process of optimizing the hyperparameters of a machine learning model to achieve the best possible performance on a given dataset. Unlike model parameters, which are learned during training, hyperparameters are set prior to training and control how the model learns.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Concepts**\n",
    "\n",
    "### **1. Model Parameters vs. Hyperparameters**\n",
    "- **Model Parameters**:  \n",
    "  These are internal values estimated from the training data during model training, such as weights in linear regression or decision thresholds in classification.\n",
    "  - Example: Coefficients in linear regression, decision boundaries in SVM.\n",
    "  \n",
    "- **Hyperparameters**:  \n",
    "  These are external configurations set before training that control the learning process. They are not learned directly from the data.  \n",
    "  - Example: Learning rate, number of estimators in a random forest, maximum depth in decision trees.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. The Importance of Hyperparameter Tuning**\n",
    "- Proper tuning of hyperparameters helps to:\n",
    "  1. Avoid underfitting and overfitting.\n",
    "  2. Improve model accuracy and generalization.\n",
    "  3. Ensure optimal use of computational resources.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Techniques for Hyperparameter Tuning**\n",
    "\n",
    "#### **(a) Manual Search**\n",
    "- Involves experimenting with different hyperparameter combinations manually.\n",
    "- Time-consuming and inefficient for large search spaces.\n",
    "\n",
    "#### **(b) Grid Search**\n",
    "- Explores all possible combinations of specified hyperparameter values.  \n",
    "- Uses **exhaustive search** over a grid of predefined values.  \n",
    "- Suitable for small datasets and limited hyperparameter combinations.  \n",
    "\n",
    "- Example:\n",
    "  - For hyperparameters:\n",
    "    - $C = [0.1, 1, 10]$  \n",
    "    - Kernel: [linear, RBF]\n",
    "  - GridSearch will test every combination:\n",
    "    - (C=0.1, Kernel=linear), (C=0.1, Kernel=RBF), etc.\n",
    "\n",
    "#### **(c) Randomized Search**\n",
    "- Randomly samples combinations of hyperparameters from specified distributions.  \n",
    "- More efficient for larger search spaces as it does not explore every combination.  \n",
    "- Provides flexibility by allowing the search to continue for a fixed number of iterations or time.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Cross-Validation in Hyperparameter Tuning**\n",
    "- Both GridSearchCV and RandomizedSearchCV use **cross-validation** to evaluate model performance for each hyperparameter combination.  \n",
    "- This ensures robust evaluation by splitting data into multiple training and validation sets.\n",
    "\n",
    "---\n",
    "\n",
    "## **GridSearchCV**\n",
    "- **Definition**: Performs exhaustive search over a grid of hyperparameter values with cross-validation.\n",
    "- **Advantages**:  \n",
    "  1. Guarantees to find the best combination from the specified grid.  \n",
    "  2. Ensures reproducibility.  \n",
    "- **Disadvantages**:  \n",
    "  1. Computationally expensive.  \n",
    "  2. Inefficient for large search spaces.\n",
    "\n",
    "---\n",
    "\n",
    "## **RandomizedSearchCV**\n",
    "- **Definition**: Samples a fixed number of hyperparameter combinations randomly from the defined search space.\n",
    "- **Advantages**:  \n",
    "  1. Faster than GridSearchCV for large search spaces.  \n",
    "  2. Can discover good combinations quickly.  \n",
    "- **Disadvantages**:  \n",
    "  1. Does not explore all combinations.  \n",
    "  2. Might miss the optimal configuration.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Key Hyperparameters for Common Models**\n",
    "- **Decision Trees**: Max depth, minimum samples split, minimum samples leaf.  \n",
    "- **SVM**: Kernel type, $C$, $\\gamma$ (gamma).  \n",
    "- **Random Forests**: Number of estimators, max features, max depth.  \n",
    "- **Neural Networks**: Learning rate, batch size, number of epochs, optimizer.\n",
    "\n",
    "---\n",
    "\n",
    "## **Steps in Hyperparameter Tuning**\n",
    "1. Select the model and define hyperparameters to tune.  \n",
    "2. Define a search strategy (GridSearchCV or RandomizedSearchCV).  \n",
    "3. Split the data using cross-validation.  \n",
    "4. Train the model for each combination and evaluate performance.  \n",
    "5. Select the hyperparameters with the best validation performance.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Challenges in Hyperparameter Tuning**\n",
    "1. **High Computational Cost**: GridSearch can be time-intensive for complex models.  \n",
    "2. **Curse of Dimensionality**: Large search spaces grow exponentially with the number of hyperparameters.  \n",
    "3. **Overfitting**: Excessive tuning on validation data may overfit to the validation set.\n",
    "\n",
    "---\n",
    "\n",
    "Hyperparameter tuning ensures that machine learning models achieve their full potential by optimizing their learning process for the given task and dataset.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
