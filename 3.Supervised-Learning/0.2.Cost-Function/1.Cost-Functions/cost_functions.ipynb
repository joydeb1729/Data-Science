{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Cost Function**\n",
    "\n",
    "A **cost function** quantifies the error or difference between the predicted outputs of a model and the actual target values. It provides a scalar value that the model seeks to minimize during training to improve its performance.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Regression Cost Functions**\n",
    "\n",
    "Regression cost functions are used when the target variable is continuous, aiming to measure the difference between predicted and actual values.\n",
    "\n",
    "### **1.1 Mean Squared Error (MSE):**\n",
    "- **Definition:** MSE calculates the average squared difference between the predicted and actual values. It penalizes larger errors more heavily due to squaring.\n",
    "- **Formula:**  \n",
    "  $$ J(\\theta) = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $$\n",
    "- **Characteristics:**\n",
    "  - Sensitive to outliers.\n",
    "  - Commonly used due to its simplicity and differentiability.\n",
    "\n",
    "---\n",
    "\n",
    "### **1.2 Root Mean Squared Error (RMSE):**\n",
    "- **Definition:** RMSE is the square root of MSE, representing the error in the same units as the target variable.\n",
    "- **Formula:**  \n",
    "  $$ J(\\theta) = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2} $$\n",
    "- **Characteristics:**\n",
    "  - Easier to interpret compared to MSE.\n",
    "  - Still sensitive to outliers.\n",
    "\n",
    "---\n",
    "\n",
    "### **1.3 Mean Absolute Error (MAE):**\n",
    "- **Definition:** MAE calculates the average of the absolute differences between predicted and actual values, treating all errors equally.\n",
    "- **Formula:**  \n",
    "  $$ J(\\theta) = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i| $$\n",
    "- **Characteristics:**\n",
    "  - More robust to outliers compared to MSE.\n",
    "  - Does not penalize larger errors more than smaller ones.\n",
    "\n",
    "---\n",
    "\n",
    "### **1.4 Coefficient of Determination ($R^2$ Score):**\n",
    "- **Definition:** $R^2$ measures the proportion of variance in the target variable explained by the model.\n",
    "- **Formula:**  \n",
    "  $$ R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2} $$\n",
    "- **Characteristics:**\n",
    "  - Ranges from 0 to 1 (higher values indicate better performance).\n",
    "  - Negative $R^2$ indicates that the model performs worse than the mean of the target variable.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Classification Cost Functions**\n",
    "\n",
    "Classification cost functions are used when the target variable is categorical, focusing on evaluating predicted probabilities or class labels.\n",
    "\n",
    "### **2.1 Binary Classification:**\n",
    "#### **Log Loss (Binary Cross-Entropy):**\n",
    "- **Definition:** Log Loss measures the performance of a classification model where the output is a probability value between 0 and 1. It penalizes predictions that are far from the actual class.\n",
    "- **Formula:**  \n",
    "  $$ J(\\theta) = -\\frac{1}{n} \\sum_{i=1}^{n} \\left[ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i) \\right] $$\n",
    "- **Characteristics:**\n",
    "  - Suitable for binary classification problems (e.g., 0 or 1).\n",
    "  - Penalizes incorrect predictions more as the predicted probability deviates from the true class.\n",
    "\n",
    "---\n",
    "\n",
    "### **2.2 Multi-Class Classification:**\n",
    "#### **Cross-Entropy Loss:**\n",
    "- **Definition:** Cross-Entropy Loss generalizes Log Loss for multi-class problems. It evaluates how well the predicted probability distribution aligns with the actual distribution.\n",
    "- **Formula:**  \n",
    "  $$ J(\\theta) = -\\frac{1}{n} \\sum_{i=1}^{n} \\sum_{j=1}^{k} y_{ij} \\log(\\hat{y}_{ij}) $$\n",
    "- **Characteristics:**\n",
    "  - Suitable for multi-class classification problems.\n",
    "  - Ensures the predicted probabilities across all classes sum to 1.\n",
    "\n",
    "---\n",
    "\n",
    "## **Summary**\n",
    "- **Regression Cost Functions:** \n",
    "  - Focus on minimizing numerical differences between predicted and actual values. Common metrics include MSE, RMSE, MAE, and $R^2$.\n",
    "- **Classification Cost Functions:** \n",
    "  - Focus on minimizing errors in predicted probabilities or class labels. Common metrics include Binary Log Loss and Multi-Class Cross-Entropy Loss.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
